{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b7cf4bd",
   "metadata": {},
   "source": [
    "<style>\n",
    ":root { --accent:#8b5cf6; --muted:#9aa0a6; }\n",
    "h1.question { font-size: 2.1rem; color: var(--accent); margin: 0 0 .35rem 0; }\n",
    "p.subtitle { font-size: 1.05rem; color: var(--muted); margin: 0 0 1rem 0; }\n",
    "hr { border: none; border-top: 1px solid #333; margin: 1rem 0; }\n",
    "code, pre, pre code { background: transparent !important; border: none !important; }\n",
    "ul { margin-top: .4rem; }\n",
    "</style>\n",
    "\n",
    "<h1 class=\"question\">Morning Drill #3 — Mini Text Analyzer (Top-3 Words)</h1>\n",
    "<p class=\"subtitle\">Loops + Multiple Functions · Difficulty: Easy–Medium</p>\n",
    "<hr/>\n",
    "\n",
    "<p>\n",
    "You’re given several short lines of text. Build a tiny analyzer that finds the\n",
    "<strong>top-3 most frequent words</strong>, with these exact cleaning rules:\n",
    "</p>\n",
    "\n",
    "<ul>\n",
    "  <li>Lowercase everything.</li>\n",
    "  <li>Treat any non-letter character (digits, punctuation, hyphens, symbols, whitespace) as a separator.</li>\n",
    "  <li>Keep words made only of letters <code>a–z</code>.</li>\n",
    "  <li>Ignore words shorter than 3 characters.</li>\n",
    "  <li>Ignore stopwords: <code>{\"the\",\"and\",\"a\",\"an\",\"to\",\"of\",\"in\",\"on\",\"for\",\"with\",\"at\",\"by\",\"is\",\"it\",\"as\"}</code>.</li>\n",
    "</ul>\n",
    "\n",
    "<p>\n",
    "Then count word frequencies and return the top 3 as a list of <code>(word, count)</code> tuples,\n",
    "sorted by <em>count descending</em>, and alphabetically to break ties.\n",
    "</p>\n",
    "\n",
    "<h3>Task</h3>\n",
    "<p><strong>Implement:</strong> <code>main(lines: list[str]) -&gt; list[tuple[str,int]]</code></p>\n",
    "\n",
    "<h3>Requirements</h3>\n",
    "<ul>\n",
    "  <li>Write and use at least <em>two</em> helper functions that you call inside <code>main</code> (e.g., a tokenizer and a sorter). Name them however you like.</li>\n",
    "  <li>Use basic loops and conditionals. Don’t use <code>re</code>/<code>regex</code> or <code>collections.Counter</code>.</li>\n",
    "  <li>Return the list of tuples; do not print.</li>\n",
    "</ul>\n",
    "\n",
    "<h3>Exact Input for Auto-Marking</h3>\n",
    "<pre><code>EXACT_INPUT = [\n",
    "  \"Data cleaning, data-cleaning, and DATA   analysis!\",\n",
    "  \"Python? Python. python; easy—as 1, 2, 3.\",\n",
    "  \"In practice, analysis & cleaning go hand-in-hand.\",\n",
    "  \"Clean data is the foundation of analysis.\"\n",
    "]</code></pre>\n",
    "\n",
    "<h3>Required Output</h3>\n",
    "<pre><code>Expected return value:\n",
    "[(\"data\", 4), (\"analysis\", 3), (\"cleaning\", 3)]</code></pre>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e381abe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- USER STARTER (implement your helpers and main) ---\n",
    "\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "STOPWORDS = {\"the\",\"and\",\"a\",\"an\",\"to\",\"of\",\"in\",\"on\",\"for\",\"with\",\"at\",\"by\",\"is\",\"it\",\"as\"}\n",
    "\n",
    "def tokenize_clean(line: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Convert a single line to lowercase, replace any non-letter with a space,\n",
    "    split into words, keep only a-z words of length >= 3, and drop stopwords.\n",
    "    Use only basic loops/conditions (no regex).\n",
    "    \"\"\"\n",
    "    # TODO: build `clean` by iterating chars and keeping letters; else add space.\n",
    "    # then split, filter by length and stopwords\n",
    "    words: List[str] = []\n",
    "    return words\n",
    "\n",
    "def add_counts(counts: Dict[str, int], words: List[str]) -> None:\n",
    "    \"\"\"\n",
    "    Update counts dict in-place using a basic for-loop.\n",
    "    \"\"\"\n",
    "    # TODO: loop and increment counts[word]\n",
    "    return None\n",
    "\n",
    "def top_n(counts: Dict[str, int], n: int) -> List[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Return the top n (word, count) sorted by count desc, then word asc.\n",
    "    Use only basic tools (you may use `sorted` with a key).\n",
    "    \"\"\"\n",
    "    # TODO: sort items as required and slice first n\n",
    "    return []\n",
    "\n",
    "def main(lines: List[str]) -> List[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Build the frequency table using your helpers and return the top 3 words.\n",
    "    \"\"\"\n",
    "    counts: Dict[str, int] = {}\n",
    "    # TODO: for each line -> tokenize_clean -> add_counts\n",
    "    # then compute top 3 via top_n and return\n",
    "    return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9dba65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Local check (use EXACT input) ---\n",
    "\n",
    "EXACT_INPUT = [\n",
    "  \"Data cleaning, data-cleaning, and DATA   analysis!\",\n",
    "  \"Python? Python. python; easy—as 1, 2, 3.\",\n",
    "  \"In practice, analysis & cleaning go hand-in-hand.\",\n",
    "  \"Clean data is the foundation of analysis.\"\n",
    "]\n",
    "EXPECTED = [(\"data\", 4), (\"analysis\", 3), (\"cleaning\", 3)]\n",
    "\n",
    "assert main(EXACT_INPUT) == EXPECTED, \"Output does not match the required top-3 list.\"\n",
    "print(\"OK — your function returns the expected top-3 list.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
